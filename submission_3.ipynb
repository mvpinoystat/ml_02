{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef5c308-3bda-41b1-b71b-fe2f7159023a",
   "metadata": {},
   "source": [
    "# **Modeling**\n",
    "public leaderboard score: 0.705   \n",
    "kaggle notebook v3   \n",
    "Rank 1636 , Jan 2, 2024  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f4c398f-e96b-4315-bed0-51a28628b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#model selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#load preprocessed dataset:\n",
    "import joblib\n",
    "#models\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa04a126-e352-42a2-b6c8-e1dee66c0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"kaggle/input/linking-writing-processes-to-writing-quality/\"\n",
    "train_logs = pd.read_csv(input_folder + \"train_logs.csv\",delimiter = \",\",header = 0)\n",
    "train_scores = pd.read_csv(input_folder +\"train_scores.csv\", delimiter = \",\", header = 0)\n",
    "scores = pd.Series(data = train_scores['score'].values, index = train_scores['id'].values, name = 'score')\n",
    "test_logs = pd.read_csv(input_folder + \"test_logs.csv\",delimiter = \",\",header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bfd31e3-a52c-4fa9-9fad-88fc1194092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering for transformer for cursor position\n",
    "class CursorPositionTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # setup the feature names\n",
    "        # self.feature_names = ['cp_sum_backstep', 'cp_n_backstep', 'cp_sum_forwardstep','cp_n_forwardstep',\n",
    "        #              'cp_change_stat', 'cp_skew_backstep', 'cp_skew_forwardstep']  \n",
    "\n",
    "        self.feature_names = ['cp_sum_backstep', 'cp_n_backstep', 'cp_sum_forwardstep','cp_n_forwardstep']\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        z = X.groupby('id')['cursor_position'].aggregate([self.cp_sum_backstep,self.cp_n_backstep, \n",
    "                     self.cp_sum_forwardstep, self.cp_n_forwardstep])\n",
    "        # make a copy of participant ids:\n",
    "        self.index_ids = z.index.values\n",
    "        return z.values\n",
    "\n",
    "    def cp_sum_backstep(self,x):\n",
    "        n1 = np.diff(np.log(x+1))\n",
    "        return np.sum(n1[n1 < 0])\n",
    "    \n",
    "    def cp_skew_backstep(self,x):\n",
    "        n1 = np.diff(np.log(x+1))\n",
    "        return st.skew(n1[n1 < 0])\n",
    "    \n",
    "    def cp_n_backstep(self,x):\n",
    "        n1 = np.diff(np.log(x+1))\n",
    "        return np.log((n1<0).sum()+1)\n",
    "    \n",
    "    def cp_sum_forwardstep(self,x):\n",
    "        n1 = np.diff(np.log(x+1))\n",
    "        return np.sum(n1[n1 > 0])\n",
    "    \n",
    "    def cp_skew_forwardstep(self,x):\n",
    "        n1 = np.diff(np.log(x+1))\n",
    "        return st.skew(n1[n1 > 0])\n",
    "    \n",
    "    def cp_n_forwardstep(self,x):\n",
    "        n1 = np.diff(np.log(x+1))\n",
    "        return np.log((n1>0).sum()+1)\n",
    "    \n",
    "    def cp_change_stat(self,x):\n",
    "        n1 = np.diff(np.log(x+1))\n",
    "        return np.std(n1, ddof = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa1c7d61-6548-4353-a292-d7bae2300246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eda wordcount transformer:\n",
    "\n",
    "# word_count feature engineering\n",
    "# Based on the graph above, we can count the number of zero changes and get the mean:\n",
    "# wc_zero_change will return the count of all non-zero steps taken by the person\n",
    "\n",
    "class WordCountTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def wc_non_zero_change(self, x):\n",
    "        n1 = np.diff(np.log(x+1))\n",
    "        n2 = np.count_nonzero(n1)\n",
    "        return n2\n",
    "    def wc_change_stat(self, x):\n",
    "        n1 = np.diff(np.log(x+1))\n",
    "        last_cutoff = n1.shape[0]-200\n",
    "        n2 = np.std(n1, ddof = 1)\n",
    "        return n2\n",
    "        \n",
    "    def transform(self, X):\n",
    "        output =  X.groupby(['id'])['word_count'].aggregate([self.wc_non_zero_change,lambda x: np.log(len(x)), \n",
    "                          lambda x: np.log(np.max(x)+1)])\n",
    "        output.columns = [\"wc_changing_nsteps\", \"wc_step_count\", \"wc_max\"]\n",
    "        self.feature_names = output.columns.values\n",
    "        self.index_ids = output.index.values\n",
    "        return output.values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7645e712-9d3e-40d4-aa02-eee5a2f18294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eda textchange transformer:\n",
    "class TextChangeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def hasChar(self, x,character:str):\n",
    "        out = 0 \n",
    "        for strings in x:\n",
    "            if character in strings:\n",
    "                out = 1\n",
    "                break\n",
    "        return out\n",
    "        \n",
    "    def transform(self, X):\n",
    "        output = X.groupby(['id'])['text_change'].aggregate([\n",
    "            (\"tc_1\", lambda x: self.hasChar(x,character = \"?\")), \n",
    "            (\"tc_2\", lambda x: self.hasChar(x,character = \"=>\")), \n",
    "            (\"tc_3\", lambda x: self.hasChar(x,character = \"(\")), \n",
    "            (\"tc_4\", lambda x: self.hasChar(x,character = \"\\\"\")), \n",
    "            (\"tc_5\", lambda x: self.hasChar(x,character = \"-\"))]) \n",
    "        self.feature_names = output.columns.values\n",
    "        self.index_ids = output.index.values\n",
    "        return output.values\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0542b309-5aed-46c2-b33b-1c6b0931372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Up Event Variable Transformer:\n",
    "class UpEventTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def find_clicked(self, x, st:str):\n",
    "        has_string = 0\n",
    "        for event in x:\n",
    "            if(event == st):\n",
    "                has_string = 1\n",
    "                break\n",
    "        return has_string\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        output = X.groupby(['id'])['up_event'].aggregate([('ue_1',lambda x: self.find_clicked(x,\"|\")),\n",
    "                                                          ('ue_2', lambda x: self.find_clicked(x,\"Shift\")),\n",
    "                                                          ('ue_3', lambda x: self.find_clicked(x,\"Tab\")),\n",
    "                                                          ])\n",
    "        self.feature_names = output.columns.values\n",
    "        self.index_ids = output.index.values\n",
    "        return output.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0acf834e-2426-429a-b6e2-db64d907af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eda action_time variable ransformer: (AT)\n",
    "\n",
    "class ActionTimeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, scores):\n",
    "        self.scores = scores\n",
    "        self.score_values = np.arange(start = 0.5, stop = 6.5, step = 0.5)\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        #Get the action time proportion or distribution per score:\n",
    "        at_init = X.groupby('id')['action_time'].aggregate([\n",
    "            ('one', lambda x: self.above_log_count(x, from_zero = 1)),\n",
    "            ('two', lambda x: self.above_log_count(x, from_zero = 2)),\n",
    "            ('three', lambda x: self.above_log_count(x, from_zero = 3)),\n",
    "            ('four', lambda x: self.above_log_count(x, from_zero = 4)),\n",
    "            ('five', lambda x: self.above_log_count(x, from_zero = 5)),\n",
    "        ])\n",
    "        \n",
    "        at_init2 = pd.merge(at_init, self.scores, left_index = True, right_index = True)\n",
    "        at2 = at_init2.groupby(by = 'score').sum()\n",
    "        self.at_proportion= at2.apply(lambda x: x/(np.sum(at2, axis = 1)))\n",
    "        return self\n",
    "        \n",
    "    def above_log_count(self, x, from_zero = 1):\n",
    "        z = np.diff(np.log(x+1))\n",
    "        z = np.abs(z)\n",
    "        if from_zero < 5:\n",
    "            count= len(list(filter(lambda q: (q>from_zero -1) and (q < from_zero), z)))\n",
    "        else:\n",
    "            count= len(list(filter(lambda q: q>=from_zero, z )))\n",
    "        return count \n",
    "        \n",
    "    def above_log_ratio(self, x, from_zero = 1):\n",
    "        z = np.diff(np.log(x+1))\n",
    "        z = np.abs(z)\n",
    "        if from_zero < 3:\n",
    "            count= len(list(filter(lambda q: (q>from_zero -1) and (q < from_zero), z)))\n",
    "        else:\n",
    "            count= len(list(filter(lambda q: q>=from_zero, z )))\n",
    "        return np.log((count+1)/len(z)) \n",
    "\n",
    "        \n",
    "    # Use chi-square to select the score of the given participant id   \n",
    "    def compute_score_by_chisquare(self, fo:pd.Series, distribution):\n",
    "        fo =fo + 1 # to remove errors for those with zero values\n",
    "        total = np.sum(fo)\n",
    "        # print(total)\n",
    "        expected_arrays = distribution * total\n",
    "        # print(expected_arrays)\n",
    "        chi_stat = []\n",
    "        for j in range(expected_arrays.shape[0]):\n",
    "            results = st.chisquare(f_obs = fo, f_exp = expected_arrays.iloc[j])\n",
    "            chi_stat.append(results[1])\n",
    "    \n",
    "        chi_stat = np.array(chi_stat)\n",
    "        # get the maximum p-value (-1) or second to the max (-2), etc\n",
    "        score_idx_1 = np.where(chi_stat == np.partition(chi_stat,-1)[-1])[0][0]\n",
    "        score_idx_2 = np.where(chi_stat == np.partition(chi_stat,-2)[-2])[0][0]\n",
    "        score_idx_3 = np.where(chi_stat == np.partition(chi_stat,-3)[-3])[0][0]\n",
    "        score_idx_4 = np.where(chi_stat == np.partition(chi_stat,-4)[-4])[0][0]\n",
    "        score_list = [\n",
    "            self.score_values[score_idx_1],\n",
    "            self.score_values[score_idx_3],\n",
    "            self.score_values[score_idx_3],\n",
    "            self.score_values[score_idx_4]]\n",
    "        \n",
    "        return np.mean(score_list)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        transform_1 = X.groupby(\"id\")['action_time'].aggregate([\n",
    "        ('at_1', lambda x: self.above_log_ratio(x, from_zero = 1)),\n",
    "        ('at_2', lambda x: self.above_log_ratio(x, from_zero = 2)),\n",
    "        ('at_3', lambda x: self.above_log_ratio(x, from_zero = 3))\n",
    "        ])\n",
    "        \n",
    "        at_init = X.groupby('id')['action_time'].aggregate([\n",
    "            ('one', lambda x: self.above_log_count(x, from_zero = 1)),\n",
    "            ('two', lambda x: self.above_log_count(x, from_zero = 2)),\n",
    "            ('three', lambda x: self.above_log_count(x, from_zero = 3)),\n",
    "            ('four', lambda x: self.above_log_count(x, from_zero = 4)),\n",
    "            ('five', lambda x: self.above_log_count(x, from_zero = 5)),\n",
    "        ])\n",
    "        transform_2 = at_init.apply(\n",
    "            lambda x: self.compute_score_by_chisquare(x, distribution = self.at_proportion),axis = 1)\n",
    "        transform_2.name = \"at_chisq\"\n",
    "        output = pd.merge(transform_1, transform_2, left_index = True, right_index = True)\n",
    "        self.feature_names = output.columns.values\n",
    "        self.index_ids = output.index.values\n",
    "        return output.values \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94f4d027-ec0f-4db3-aa93-3d398a464359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer for Activity, act:\n",
    "class ActivityTransformer(BaseEstimator, TransformerMixin):\n",
    "    oneHot: OneHotEncoder\n",
    "    scores: pd.Series\n",
    "    act_dist: pd.DataFrame\n",
    "    feature_names: np.array\n",
    "    initial_features: np.array\n",
    "    \n",
    "    def __init__(self, scores:pd.Series):\n",
    "        self.oneHot = OneHotEncoder(handle_unknown = 'ignore', categories = 'auto', sparse_output = False)\n",
    "        self.scores = scores\n",
    "        self.score_values = np.arange(start = 0.5, stop = 6.5, step = 0.5)\n",
    "        self.initial_features = np.array(['ac_Input', 'ac_Move', 'ac_NonPro', 'ac_Paste', 'ac_RemCut', 'ac_Replace'])\n",
    "        \n",
    "    def fit(self,X, y=None):\n",
    "        #Transform X labels first:\n",
    "        #Transform all with move into a Move:\n",
    "        X.activity = X.activity.apply(lambda x: \"Move\" if (\"Move\" in x) else x)\n",
    "        #Encode then get the distribution\n",
    "        self.oneHot.fit(X)\n",
    "        a1 = self.oneHot.fit_transform(X.activity.values.reshape(-1,1))\n",
    "        a2 = pd.DataFrame(data=a1, columns=self.initial_features)\n",
    "        a2['id'] = X.id.copy()\n",
    "        \n",
    "        act = a2.groupby(by = \"id\").sum()\n",
    "        act = act + 1 # to avoid expected value of zero\n",
    "        \n",
    "        # Get the distribution for each kind of score\n",
    "        # act distribution:\n",
    "        act_dist = pd.merge(act, scores, left_index = True, right_index = True)\n",
    "        act_dist = act_dist.groupby('score').sum()\n",
    "        \n",
    "        row_total = np.sum(act_dist, axis = 1)\n",
    "        self.act_dist = act_dist.apply(lambda x: x / row_total)\n",
    "            \n",
    "        return self\n",
    "\n",
    "\n",
    "    def compute_score_by_chisquare(self, fo:pd.Series, distribution):\n",
    "        fo = fo+1\n",
    "        total = np.sum(fo)\n",
    "        # print(total)\n",
    "        # add 1 to avoid expected value of zero.\n",
    "        expected_arrays = distribution * total \n",
    "        # print(expected_arrays)\n",
    "        chi_stat = []\n",
    "        for j in range(expected_arrays.shape[0]):\n",
    "            results = st.chisquare(f_obs = fo, f_exp = expected_arrays.iloc[j])\n",
    "            chi_stat.append(results[1])\n",
    "    \n",
    "        chi_stat = np.array(chi_stat)\n",
    "        # get the maximum p-value (-1) \n",
    "        score_idx_1 = np.where(chi_stat == np.partition(chi_stat,-1)[-1])[0][0]\n",
    "        \n",
    "        return self.score_values[score_idx_1]\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        #Transform X labels first:\n",
    "        #Transform all with move into a Move:\n",
    "        X.activity = X.activity.apply(lambda x: \"Move\" if (\"Move\" in x) else x)\n",
    "        \n",
    "        pre_output = self.oneHot.transform(X['activity'].values.reshape(-1,1))\n",
    "        a2 = pd.DataFrame(data = pre_output, columns = self.initial_features)\n",
    "        a2['id'] = X.id \n",
    "        act = a2.groupby('id').sum()\n",
    "        output = act.apply(lambda x: self.compute_score_by_chisquare(x, self.act_dist), axis = 1)\n",
    "        output.name = \"act_chisq\"\n",
    "        self.feature_names = output.name\n",
    "        return output.values.reshape(-1,1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47e88c0-5c7d-4bdd-a8a3-e7e426d09f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to combine summary:\n",
    "cp_pipe = Pipeline([('cp_tx', CursorPositionTransformer())])\n",
    "wc_pipe = Pipeline([('wc_tx', WordCountTransformer())])\n",
    "tc_pipe = Pipeline([('tc_tx', TextChangeTransformer())])\n",
    "ue_pipe = Pipeline([('ue_tx', UpEventTransformer())])\n",
    "at_pipe = Pipeline([('at_tx', ActionTimeTransformer(scores = scores))])\n",
    "act_pipe = Pipeline([(\"act_tx\", ActivityTransformer(scores))])\n",
    "\n",
    "#join the pipes:\n",
    "main_pipe = FeatureUnion(transformer_list = [\n",
    "    ('cp_pipe', cp_pipe),\n",
    "    ('wc_pipe', wc_pipe),\n",
    "    ('tc_pipe', tc_pipe),\n",
    "    ('ue_pipe', ue_pipe),\n",
    "    ('at_pipe', at_pipe),\n",
    "    ('act_pipe', act_pipe)])\n",
    "\n",
    "final_pipe = Pipeline([('main_pipe', main_pipe),\n",
    "                        ('Poly', PolynomialFeatures(degree = 2, include_bias = False)),\n",
    "                        ('Scaler', StandardScaler())\n",
    "                         ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f08b297-4c38-4412-ba89-82b7af658f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_pipe.fit_transform(train_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fbb30ac-95b0-4ca3-83a8-be841e6d2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = main_pipe.named_transformers['cp_pipe'].named_steps['cp_tx'].index_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c64307-1421-4d48-bedb-29ed573d7183",
   "metadata": {},
   "source": [
    "# **Modeling Portion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11bc907a-4258-4d41-bc1d-5d1a4c3a73e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dum main pipe\n",
    "#joblib.dump(X, \"transformed_train.pkl\")\n",
    "#joblib.dump(train_ids, \"train_ids.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c654a910-a69b-4555-b362-0aa73d78c185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2471,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = scores.values\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da29b287-ff50-41b3-a7c6-ec853d118b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6059289685412605\n"
     ]
    }
   ],
   "source": [
    "model = BaggingRegressor(estimator = SVR(C=10000, epsilon = 0.0001), max_samples = 400, \n",
    "                         n_estimators = 100, random_state = 11)\n",
    "model.fit(X,Y)\n",
    "#remove below:\n",
    "rmse = np.sqrt(mean_squared_error(model.predict(X), Y))\n",
    "print(\"RMSE: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f161a10-c47f-4357-889e-f5278efb0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction:\n",
    "\n",
    "X_test = final_pipe.transform(test_logs)\n",
    "test_ids = test_logs.id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b3e5c7-c58e-4f7e-af48-4beeef749b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)\n",
    "submission = pd.DataFrame({'id':test_ids, 'score':prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f040c1e-14f4-43fb-adbe-95a176a74553",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
